General design: 
	- name all folder with "_" and standard english letters to avoid messed up pathing
	- Relative filepaths
		- use "/" instead of "\" as the latter is an escape character in
	  python
	- use functions
	- explain everything with comments
	- try to avoid hardcoded strings as arguments (use variables / constants so it still matches if changed)
	- pipeline executor files to run pipeline in modules
	- pipeline executor handles conditionals (eg differing folder structures), then have 
	  different subprocesses for each condition, no conditionals in subprocesses.
	  The pipeline executor is the master brain, the subprocesses are just workers
	  --> easier bugfixing
	- BUT: subprocesses should be able to handle different file types (for example)
	  with the instruction on which one to do coming as an argument from the executor
	  so it remains in charge of decision making
	- data is parsed between executor and subprocesses as either a serialzed JSON object 
	  or as a filepath to a resulting temporary file in /tmp 
	- temporary files can be permanently saved to a copy if specified
	- all termporary files are automatically deleted after the pipeline finishes


Error Handling Philosophy for Thesis & Reusable Code

    ✅ Add minimal, practical error checks (e.g., missing files, wrong paths)

    ✅ Provide clear, readable error messages for common user mistakes

    ✅ Prioritize code I can reliably re-run months later without debugging (this is why comments and error handling are important)

    ✅ Keep GitHub repos clean and understandable to show competence, but avoid over-engineering


For future projects:
- at the very beginning, run a script to standardize raw data format
	(eg takes a directory with any format, saves all files a h5ad to another directory and gives them
	 distincitve names eg standardized_GDC_glioma_cancerous_1.h5ad)
